% Chapter Template

\chapter{Phase 4 - Analyzing Data} % Main chapter title

\label{Chapter7} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
The goal with this phase is to use the language python combined with mysql quires to get the data from the database. Clean the data and then analyse the results and test it for statistical significance.

\section{Work process}
The main technologies used for this phase was Python using several different libraries and mysql to querie the database in Seul, South Korea.

data gathering process:
To gather the data from the MySQL database several queries were made with conditions that specified what specific data to be gathered. This data then loaded into a data frame in python. Eight different data frames were created. Four containing information about the user's actions on each question these were the following: English speaking BBC users,  Chinese BBC users,  English QQ and Chinese QQ users. Four other data frames with the same constraints were created but instead of containing the user's responses and times it took to answer the different questions, these contained the users questionnaire answers.
\\\\
Once the data was gathered is was scanned for irregularities these were often either removed or replaced by a mean value as is commonly done in machine learning and other data mining/data analysis fields. The most obvious errors were the ones where the data had the wrong shape because of a bug. These were simply fixed or removed one example of this is one user who had twice the amount of answers to the questions with the exact same information. In that case, one of each row containing a duplicate was simply removed. Another type of faulty data where the user's complete input was removed was the cases where a user had skipped through all his/her questions. Resulting in all incorrect answers with times spent on each question close to zero, these users were simply removed another type that was removed were users who did the test from a mobile device. From this type of data cleaning, 16 users were removed (total users was calculated after these had been removed). Another type of data that needed to be cleaned where some questions where the users simply had an extremely high mean time of a question that was out of proportion to the rest of the mean times. This seemed to happen randomly and is likely due to a user leaving the test to do something else and then return. In these cases, a cap of 400 seconds where set and any question mean-time that was higher than that was removed. The 400-second cap was used because the largest normal average was around 100-200 seconds after that we only got a couple of odd outliers with times from 500 seconds and up. There were some smaller oddities that had to be handled as well but we will not go into these in detail in this report. The data was removed by two different ways, if a user had to be removed it was simply unselected in the SQL query to the database. If on the other hand a value had to be modified or a single question result dropped this was done in the python script on the data frame.



 
%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\section{Analysis }
To analyse whether the differences in mean correct results from the BBC site and the QQ site were statistically significant, I first calculated the average proportion of correct responses from each respective site per question. Specifically, I used Python to find the average correct responses for each group as well as to plot these results on a bar graph (see figure xx). Additionally, for both sites, I calculated the average amount of time it took per user to submit their answer given that the users' answer was correct. The number of seconds it took users per question, on average, to find the accurate answers were then plotted as bar graph using Python (see figure xx). Finally, to examine whether the differences in mean time and proportion of accurate answers for English versus Chinese users on the BBC and QQ sites were statistically significant, I performed an independent samples t-test analysis on the mean values using Python. 

\section{Questionnaire }
At the end of the study, users were requested to complete a set of 11 self-reported questionnaire questions gauging the likeability of the site design (e.g. "I liked the design of the site", "The design of this site was unusual to me", etc.) and perceived navigability of the site (e.g., "I thought this site was easy to use", "I felt very confident in using the site", etc.).  Users were asked to respond to the questions on a 1 to 5 Likert scale, where 1 reflected strongly disagree and 5 represented strongly agree. However, the directionality of the responses - if they reflected positive or negative perceptions of the sites - depended on the weight of the questions (i.e., "I liked the design of the site" reflects a positively weighted question while "I felt overwhelmed using this site" reflects a negative weight). Given that the directionality of the questions was not uniform, I first normalized the data prior to calculating the overall likeability of the BBC and QQ sites. Additionally, I dropped responses from question two as this question simply asks users whether they believe the news site was similar to other news sites, as this does not measure likeability or navigability of the site, it was excluded from this analysis. 
